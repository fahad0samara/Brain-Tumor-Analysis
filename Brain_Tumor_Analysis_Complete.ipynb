{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Analysis Complete Notebook\n",
    "This notebook contains the complete analysis pipeline with proper handling of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('Brain_Tumor_Prediction_Dataset.csv')\n",
    "\n",
    "# Display initial information\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean the data by handling missing values and outliers\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"Initial Missing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Fill missing values in categorical columns\n",
    "    categorical_cols = ['Treatment_Received', 'Gender', 'Brain_Tumor_Present']\n",
    "    for col in categorical_cols:\n",
    "        if df[col].isnull().any():\n",
    "            mode_value = df[col].mode()[0]\n",
    "            df[col].fillna(mode_value, inplace=True)\n",
    "            print(f\"\\nFilled {col} missing values with mode: {mode_value}\")\n",
    "    \n",
    "    # Handle missing values in numerical columns\n",
    "    numeric_cols = ['Age', 'Tumor_Size', 'Genetic_Risk', 'Survival_Rate(%)']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"Missing values: {df[col].isnull().sum()}\")\n",
    "        \n",
    "        if df[col].isnull().any():\n",
    "            median_value = df[col].median()\n",
    "            df[col].fillna(median_value, inplace=True)\n",
    "            print(f\"Filled missing values with median: {median_value:.2f}\")\n",
    "        \n",
    "        # Handle outliers using IQR\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count outliers\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        print(f\"Found {len(outliers)} outliers\")\n",
    "        \n",
    "        # Clip outliers\n",
    "        df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "    \n",
    "    # Final check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nWarning: Still have missing values:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"\\nSuccess: No missing values remain in the dataset!\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create advanced features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Risk Score (weighted combination of risk factors)\n",
    "    df['Risk_Score'] = (\n",
    "        df['Genetic_Risk'] * 0.4 +\n",
    "        df['Age'].clip(0, 100) / 100 * 0.3 +\n",
    "        df['Tumor_Size'] / df['Tumor_Size'].max() * 0.3\n",
    "    )\n",
    "    \n",
    "    # Medical complexity (count of high-risk factors)\n",
    "    df['Medical_Complexity'] = df.apply(lambda x: sum([\n",
    "        x['Genetic_Risk'] > 7,  # High genetic risk\n",
    "        x['Age'] > 50,          # Advanced age\n",
    "        x['Tumor_Size'] > 3,    # Large tumor\n",
    "        x['Survival_Rate(%)'] < 50  # Low survival rate\n",
    "    ]), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Features for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features for ML\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert Gender to numeric\n",
    "    gender_map = {'Female': 0, 'Male': 1, 'Other': 2}\n",
    "    df['Gender'] = df['Gender'].map(gender_map)\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = ['Age', 'Gender', 'Tumor_Size', 'Genetic_Risk', 'Survival_Rate(%)',\n",
    "                   'Risk_Score', 'Medical_Complexity']\n",
    "    \n",
    "    # Create X and y\n",
    "    X = df[feature_cols]\n",
    "    y = df['Brain_Tumor_Present'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean data\n",
    "print(\"Cleaning and preprocessing data...\")\n",
    "df_cleaned = clean_data(df)\n",
    "\n",
    "# Engineer features\n",
    "print(\"\\nEngineering features...\")\n",
    "df_processed = engineer_features(df_cleaned)\n",
    "\n",
    "# Prepare features\n",
    "print(\"\\nPreparing features...\")\n",
    "X, y = prepare_features(df_processed)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "print(\"\\nTraining models...\")\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nResults for {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # For Random Forest, show feature importance\n",
    "    if name == 'Random Forest':\n",
    "        importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        print(\"\\nFeature Importance:\")\n",
    "        print(importance)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=importance, x='Importance', y='Feature')\n",
    "        plt.title('Feature Importance in Random Forest Model')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
